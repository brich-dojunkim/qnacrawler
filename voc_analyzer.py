import json
import pandas as pd
import numpy as np
from collections import Counter
from datetime import datetime
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class CategoryBasedVoCAnalyzer:
    def __init__(self, json_file_path: str):
        """
        ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            json_file_path: í¬ë¡¤ë§ëœ JSON íŒŒì¼ ê²½ë¡œ
        """
        self.json_file_path = json_file_path
        self.df = None
        self.load_and_preprocess_data()
        
    def load_and_preprocess_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        try:
            with open(self.json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ë°ì´í„° êµ¬ì¡° í™•ì¸
            if 'data' in data:
                qna_data = data['data']
            else:
                qna_data = data
            
            self.df = pd.DataFrame(qna_data)
            
            # ì¹´í…Œê³ ë¦¬ ì •ë³´ í‰íƒ„í™”
            if 'category' in self.df.columns:
                category_df = pd.json_normalize(self.df['category'])
                self.df = pd.concat([self.df.drop('category', axis=1), category_df], axis=1)
            
            # ë‚ ì§œ ë³€í™˜
            if 'registration_date' in self.df.columns:
                self.df['registration_date'] = pd.to_datetime(self.df['registration_date'], errors='coerce')
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
            if 'question_content' in self.df.columns:
                self.df['content_length'] = self.df['question_content'].str.len()
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df)}ê°œ ë¬¸ì˜")
            print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(self.df.columns)}")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def analyze_by_assigned_team(self) -> Dict:
        """assigned_team ê¸°ì¤€ ë¶„ì„"""
        print("ğŸ¢ íŒ€ë³„ ì‹¤ì œ ë¬¸ì˜ ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        if 'assigned_team' not in self.df.columns or 'question_content' not in self.df.columns:
            return {"error": "í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        team_analysis = {}
        
        for team in self.df['assigned_team'].dropna().unique():
            team_data = self.df[self.df['assigned_team'] == team]
            
            if len(team_data) < 3:  # ìµœì†Œ 3ê°œ ì´ìƒ
                continue
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = {
                'total_inquiries': len(team_data),
                'urgent_count': team_data['is_urgent'].sum() if 'is_urgent' in team_data.columns else 0,
                'answered_count': len(team_data[team_data['answer_status'] == 'ë‹µë³€ì™„ë£Œ']) if 'answer_status' in team_data.columns else 0,
                'avg_content_length': round(team_data['content_length'].mean(), 1) if 'content_length' in team_data.columns else 0
            }
            
            # ëŒ€í‘œ ë¬¸ì˜ ì‚¬ë¡€ë“¤ (ë‹¤ì–‘í•œ ê¸¸ì´ë¡œ 2ê°œë§Œ)
            samples = []
            if 'content_length' in team_data.columns:
                sorted_data = team_data.sort_values('content_length')
                
                for quantile in [0.3, 0.7]:  # 2ê°œë§Œ
                    idx = int(len(sorted_data) * quantile)
                    if idx < len(sorted_data):
                        sample = sorted_data.iloc[idx]
                        samples.append({
                            'inquiry_id': sample.get('inquiry_id', 'N/A'),
                            'content': sample['question_content'],
                            'length': sample['content_length'],
                            'sub_category': sample.get('sub_category', 'N/A'),
                            'is_urgent': sample.get('is_urgent', False)
                        })
            
            # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ ë¶„í¬
            sub_categories = {}
            if 'sub_category' in team_data.columns:
                sub_cat_counts = team_data['sub_category'].value_counts().head(5)  # ìƒìœ„ 5ê°œë§Œ
                sub_categories = sub_cat_counts.to_dict()
            
            team_analysis[team] = {
                'basic_info': basic_info,
                'sample_inquiries': samples,
                'sub_categories': sub_categories
            }
        
        return team_analysis

    def analyze_by_sub_category(self) -> Dict:
        """sub_category ê¸°ì¤€ ë¶„ì„"""
        print("ğŸ“‚ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ ì‹¤ì œ ë¬¸ì˜ ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        if 'sub_category' not in self.df.columns or 'question_content' not in self.df.columns:
            return {"error": "í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        category_analysis = {}
        
        for category in self.df['sub_category'].dropna().unique():
            cat_data = self.df[self.df['sub_category'] == category]
            
            if len(cat_data) < 3:
                continue
            
            # ê¸°ë³¸ ì •ë³´
            basic_info = {
                'total_inquiries': len(cat_data),
                'urgent_count': cat_data['is_urgent'].sum() if 'is_urgent' in cat_data.columns else 0,
                'avg_content_length': round(cat_data['content_length'].mean(), 1) if 'content_length' in cat_data.columns else 0
            }
            
            # ì´ ì¹´í…Œê³ ë¦¬ê°€ ì£¼ë¡œ ì–´ëŠ íŒ€ì—ì„œ ì²˜ë¦¬ë˜ëŠ”ì§€
            team_distribution = {}
            if 'assigned_team' in cat_data.columns:
                team_counts = cat_data['assigned_team'].value_counts()
                team_distribution = team_counts.to_dict()
            
            # ëŒ€í‘œ ë¬¸ì˜ ì‚¬ë¡€ë“¤ (2ê°œë§Œ)
            samples = []
            for i in range(min(2, len(cat_data))):
                sample = cat_data.iloc[i]
                samples.append({
                    'inquiry_id': sample.get('inquiry_id', 'N/A'),
                    'content': sample['question_content'][:150] + '...' if len(sample['question_content']) > 150 else sample['question_content'],
                    'assigned_team': sample.get('assigned_team', 'N/A'),
                    'length': sample.get('content_length', 0)
                })
            
            category_analysis[category] = {
                'basic_info': basic_info,
                'team_distribution': team_distribution,
                'sample_inquiries': samples
            }
        
        return category_analysis

    def analyze_weekly_trends(self) -> Dict:
        """ì£¼ê°„ë³„ ë¬¸ì˜ íŠ¸ë Œë“œ"""
        print("ğŸ“… ì£¼ê°„ë³„ ë¬¸ì˜ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
        
        if 'registration_date' not in self.df.columns:
            return {"error": "registration_date ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        # ì£¼ê°„ë³„ ì§‘ê³„ (ì›”ìš”ì¼ ì‹œì‘)
        self.df['year_week'] = self.df['registration_date'].dt.to_period('W-MON')
        weekly_stats = {}
        
        # ìµœê·¼ 12ì£¼ê°„ë§Œ ë¶„ì„
        recent_weeks = self.df['year_week'].dropna().unique()
        recent_weeks = sorted(recent_weeks)[-12:]
        
        for week in recent_weeks:
            week_data = self.df[self.df['year_week'] == week]
            
            stats = {
                'total_inquiries': len(week_data),
                'urgent_count': week_data['is_urgent'].sum() if 'is_urgent' in week_data.columns else 0,
                'avg_content_length': round(week_data['content_length'].mean(), 1) if 'content_length' in week_data.columns else 0
            }
            
            # íŒ€ë³„ ë¶„í¬ (ìƒìœ„ 3ê°œë§Œ)
            if 'assigned_team' in week_data.columns:
                team_dist = week_data['assigned_team'].value_counts().head(3).to_dict()
                stats['top_teams'] = team_dist
            
            weekly_stats[str(week)] = stats
        
        return weekly_stats

    def get_overall_summary(self) -> Dict:
        """ì „ì²´ ë°ì´í„° ìš”ì•½"""
        summary = {
            'total_inquiries': len(self.df),
            'date_range': {
                'start': str(self.df['registration_date'].min().date()) if 'registration_date' in self.df.columns else None,
                'end': str(self.df['registration_date'].max().date()) if 'registration_date' in self.df.columns else None
            }
        }
        
        # íŒ€ ê°œìˆ˜ ë° ëª©ë¡
        if 'assigned_team' in self.df.columns:
            teams = self.df['assigned_team'].dropna().unique()
            summary['teams'] = {
                'count': len(teams),
                'list': teams.tolist()
            }
        
        # ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ ë° ëª©ë¡
        if 'sub_category' in self.df.columns:
            categories = self.df['sub_category'].dropna().unique()
            summary['categories'] = {
                'count': len(categories),
                'list': categories.tolist()
            }
        
        # ê¸°ë³¸ í†µê³„
        if 'is_urgent' in self.df.columns:
            summary['urgent_count'] = int(self.df['is_urgent'].sum())
        
        if 'answer_status' in self.df.columns:
            answer_stats = self.df['answer_status'].value_counts().to_dict()
            summary['answer_status_distribution'] = answer_stats
        
        if 'content_length' in self.df.columns:
            summary['content_length_stats'] = {
                'mean': round(self.df['content_length'].mean(), 1),
                'median': round(self.df['content_length'].median(), 1),
                'min': int(self.df['content_length'].min()),
                'max': int(self.df['content_length'].max())
            }
        
        return summary

    def generate_category_voc_analysis(self, verbose=False) -> Dict:
        """ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„ ì‹¤í–‰"""
        if verbose:
            print("ğŸ¯ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„ ì‹œì‘...")
        
        results = {
            "analysis_timestamp": datetime.now().isoformat(),
            "data_source": self.json_file_path,
            "overall_summary": self.get_overall_summary()
        }
        
        # 1. íŒ€ë³„ ë¶„ì„
        if verbose:
            print("1ï¸âƒ£ íŒ€ë³„ ë¶„ì„...")
        results["team_analysis"] = self.analyze_by_assigned_team()
        
        # 2. ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        if verbose:
            print("2ï¸âƒ£ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„...")
        results["category_analysis"] = self.analyze_by_sub_category()
        
        # 3. ì£¼ê°„ë³„ íŠ¸ë Œë“œ
        if verbose:
            print("3ï¸âƒ£ ì£¼ê°„ë³„ íŠ¸ë Œë“œ...")
        results["weekly_trends"] = self.analyze_weekly_trends()
        
        # ê²°ê³¼ ì €ì¥
        if verbose:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"category_voc_analysis_{timestamp}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"âœ… ì¹´í…Œê³ ë¦¬ VoC ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
        
        return results

    def create_summary_dashboard(self) -> str:
        """ê°„ë‹¨í•œ ìš”ì•½ ëŒ€ì‹œë³´ë“œ"""
        summary = self.get_overall_summary()
        
        dashboard = f"""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘                ğŸ“Š ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„                        â•‘
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ ğŸ“ˆ ë°ì´í„° ê°œìš”                                                â•‘
        â•‘   â€¢ ì´ ë¬¸ì˜: {summary['total_inquiries']:,}ê±´                      â•‘
        â•‘   â€¢ ë¶„ì„ ê¸°ê°„: {summary['date_range']['start']} ~ {summary['date_range']['end']} â•‘
        â•‘   â€¢ ë‹´ë‹¹íŒ€: {summary.get('teams', {}).get('count', 0)}ê°œ                â•‘
        â•‘   â€¢ ì„¸ë¶€ì¹´í…Œê³ ë¦¬: {summary.get('categories', {}).get('count', 0)}ê°œ          â•‘
        """
        
        if 'urgent_count' in summary:
            dashboard += f"â•‘   â€¢ ê¸´ê¸‰ ë¬¸ì˜: {summary['urgent_count']}ê±´                        â•‘\n"
        
        if 'content_length_stats' in summary:
            avg_length = summary['content_length_stats']['mean']
            dashboard += f"â•‘   â€¢ í‰ê·  ë¬¸ì˜ ê¸¸ì´: {avg_length}ì                          â•‘\n"
        
        dashboard += """â•‘                                                              â•‘
        â•‘ ğŸ¯ ë¶„ì„ ë‚´ìš©                                                  â•‘
        â•‘   â€¢ íŒ€ë³„ ì‹¤ì œ ë¬¸ì˜ ë‚´ìš© ë° í‚¤ì›Œë“œ                              â•‘
        â•‘   â€¢ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì˜ íŠ¹ì„±                                  â•‘
        â•‘   â€¢ ì£¼ê°„ë³„ ë¬¸ì˜ íŠ¸ë Œë“œ                                        â•‘
        â•‘   â€¢ ëŒ€í‘œ ë¬¸ì˜ ì‚¬ë¡€                                            â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        
        return dashboard

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    import os
    
    # JSON íŒŒì¼ ì°¾ê¸°
    json_files = [f for f in os.listdir('.') if f.endswith('.json') and 'qna' in f.lower()]
    
    if not json_files:
        print("âŒ Q&A JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
    json_file = max(json_files, key=os.path.getctime)
    print(f"ğŸ“ ë¶„ì„í•  íŒŒì¼: {json_file}")
    
    try:
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = CategoryBasedVoCAnalyzer(json_file)
        
        # ëŒ€ì‹œë³´ë“œ ì¶œë ¥
        print(analyzer.create_summary_dashboard())
        
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„ ì‹¤í–‰
        results = analyzer.generate_category_voc_analysis(verbose=True)
        
        # HTML ë³´ê³ ì„œ ìƒì„±
        try:
            from voc_html_reporter import CategoryVoCHTMLReporter
            
            html_reporter = CategoryVoCHTMLReporter(analyzer.df)
            html_filename = html_reporter.save_and_open_html_report(results)
            
            print(f"\nğŸ‰ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ VoC ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“„ HTML ë³´ê³ ì„œ: {html_filename}")
            
        except ImportError:
            print("HTML ë¦¬í¬í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. voc_html_reporter.py íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        print("\nğŸ’¡ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        
        if 'team_analysis' in results:
            team_count = len(results['team_analysis'])
            print(f"ğŸ“Š ë¶„ì„ëœ íŒ€: {team_count}ê°œ")
            
            if results['team_analysis']:
                # ê°€ì¥ ë¬¸ì˜ê°€ ë§ì€ íŒ€
                max_team = max(results['team_analysis'].items(), 
                             key=lambda x: x[1]['basic_info']['total_inquiries'])
                print(f"ğŸ“ˆ ìµœë‹¤ ë¬¸ì˜ íŒ€: {max_team[0]} ({max_team[1]['basic_info']['total_inquiries']}ê±´)")
        
        if 'category_analysis' in results:
            cat_count = len(results['category_analysis'])
            print(f"ğŸ“‚ ë¶„ì„ëœ ì„¸ë¶€ì¹´í…Œê³ ë¦¬: {cat_count}ê°œ")
        
        if 'weekly_trends' in results:
            week_count = len(results['weekly_trends'])
            print(f"ğŸ“… ë¶„ì„ëœ ì£¼ê°„: {week_count}ì£¼")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()